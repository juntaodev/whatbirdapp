# ğŸ¦ WhatBirdApp

An intelligent mobile and web platform that identifies birds from recorded sounds using machine learning and signal processing.

---

## ğŸ“˜ Overview

**WhatBirdApp** enables users to record or upload a short bird sound clip, and the system identifies the most likely bird species.  
The app combines audio feature extraction (Mel spectrograms), a trained bird song classifier (BirdNET / custom CNN), and a simple, user-friendly mobile interface.

---

## ğŸš€ Features

- ğŸ¤ Record or upload bird sounds directly from the app  
- ğŸ§  Identify bird species using pre-trained ML models  
- ğŸŒ Offline or online inference support  
- ğŸ“Š Display confidence scores and additional info (habitat, song pattern, map)  
- ğŸ§© Modular architecture (frontend + backend + ML)  

---

## ğŸ§© Architecture

```

Frontend (Flutter)
â†“
REST API (FastAPI)
â†“
ML Model Server (BirdNET or Custom CNN)
â†“
Database / Storage (PostgreSQL, MinIO, or Firebase)

```

---

## ğŸ“ Repository Structure

```

whatbirdapp/
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ services/
â”‚   â””â”€â”€ models/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ assets/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ training/
â”‚   â””â”€â”€ utils/
â””â”€â”€ docs/
â”œâ”€â”€ roadmap.md
â””â”€â”€ architecture-diagram.png

````

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/juntaoliudev/whatbirdapp.git
cd whatbirdapp
````

### 2ï¸âƒ£ Set Up Python Backend

```bash
cd backend
python -m venv venv
source venv/bin/activate   # or venv\Scripts\activate (Windows)
pip install -r requirements.txt
uvicorn main:app --reload
```

### 3ï¸âƒ£ Set Up Flutter Frontend

```bash
cd frontend
flutter pub get
flutter run
```

---

## ğŸ§  Model Integration

The system supports either:

* **BirdNET Model** (pre-trained) â€” for baseline performance
* **Custom CNN Model** â€” trained using spectrograms from open datasets

Model files go under `ml/models/` and are auto-loaded at backend startup.

---

## ğŸ§ª Development Workflow

| Branch      | Purpose                      |
| ----------- | ---------------------------- |
| `main`      | Stable production-ready code |
| `dev`       | Active development           |
| `feature/*` | Feature branches             |

```bash
git checkout -b feature/audio-upload
git add .
git commit -m "feat: add audio upload endpoint"
git push origin feature/audio-upload
```

---

## âœ… Phase 0 Deliverables

* Git repo initialized and connected to GitHub
* Backend and frontend skeletons created
* Initial `README.md` and `.gitignore` added
* Basic CI checks (optional GitHub Actions) configured

---

## ğŸ“œ License

MIT License Â© 2025 Juntao Liu

---

## ğŸ‘¥ Contributors

* **Juntao Liu** â€” Lead Developer
* [Optional teammates or collaborators]

---

## ğŸ“š Resources

* [BirdNET Research Paper (Cornell Lab of Ornithology)](https://birdnet.cornell.edu/)
* [TensorFlow Audio Classification Tutorial](https://www.tensorflow.org/tutorials/audio/simple_audio)
* [Flutter + FastAPI Integration Guide](https://fastapi.tiangolo.com/tutorial/)

```
